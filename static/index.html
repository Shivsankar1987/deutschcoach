<!DOCTYPE html>
<html lang="de">
<head>
  <meta charset="UTF-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0, viewport-fit=cover" />
  <title>DeutschCoach (√ñsterreich)</title>

  <style>
    :root { color-scheme: light; }
    body {
      font-family: system-ui, -apple-system, Segoe UI, Roboto, sans-serif;
      margin: 0;
      padding: 18px;
      padding-bottom: calc(18px + env(safe-area-inset-bottom));
      background: #fff;
    }
    .container { max-width: 640px; margin: 0 auto; }
    .topbar { display:flex; align-items:center; justify-content:space-between; gap:10px; }
    h1 { font-size: 28px; margin: 10px 0 14px; }
    a { color:#0b57d0; text-decoration:none; font-weight:600; }
    .row { margin: 10px 0; }
    button, select {
      width: 100%;
      font-size: 18px;
      padding: 14px;
      border-radius: 12px;
      border: 1px solid #ddd;
      background: #f4f4f4;
    }
    button:active { transform: scale(0.99); }
    .box {
      border: 1px solid #ddd;
      padding: 12px;
      margin-top: 10px;
      border-radius: 12px;
      background: #fff;
    }
    .label { font-weight: 700; margin-bottom: 6px; }
    #talkBtn { touch-action: none; }
    audio { width: 100%; margin-top: 10px; }
    .small { opacity:0.65; font-size: 12px; margin-top: 6px; }
  </style>
</head>

<body>
  <div class="container">
    <div class="topbar">
      <h1>DeutschCoach (√ñsterreich)</h1>
      <a href="/logout">Logout</a>
    </div>

    <div class="row">
      <label class="label" for="mode">Mode</label>
      <select id="mode">
        <option value="chat">üó£ Chat</option>
        <option value="correct">‚úèÔ∏è Correct my sentence</option>
        <option value="roleplay">üé≠ Roleplay</option>
        <option value="quiz">üß† Mini quiz</option>
      </select>
      <div class="small">Tipp: F√ºr iPhone/iPad bitte in Safari √∂ffnen.</div>
    </div>

    <div class="row">
      <button id="talkBtn">üé§ Hold to talk</button>
      <button id="resetBtn">üîÑ Reset Conversation</button>
    </div>

    <div class="box">
      <div class="label">Mic status</div>
      <div id="micStatus">‚Äî</div>
    </div>

    <div class="box">
      <div class="label">You said</div>
      <div id="transcript">‚Äî</div>
    </div>

    <div class="box">
      <div class="label">Coach</div>
      <div id="reply">‚Äî</div>
    </div>

    <audio id="player" controls></audio>

    <script>
      let mediaRecorder = null;
      let chunks = [];
      let isRecording = false;
      let currentStream = null; // ‚úÖ important for iOS multi-turn

      let sessionId = localStorage.getItem("sessionId") || "";

      const talkBtn = document.getElementById("talkBtn");
      const resetBtn = document.getElementById("resetBtn");
      const modeEl = document.getElementById("mode");

      const micStatusEl = document.getElementById("micStatus");
      const transcriptEl = document.getElementById("transcript");
      const replyEl = document.getElementById("reply");
      const player = document.getElementById("player");

async function blobToArrayBuffer(blob) {
  return await blob.arrayBuffer();
}

function writeWavHeader(view, sampleRate, numChannels, numFrames) {
  const bytesPerSample = 2;
  const blockAlign = numChannels * bytesPerSample;
  const byteRate = sampleRate * blockAlign;
  const dataSize = numFrames * blockAlign;

  function writeString(offset, str) {
    for (let i = 0; i < str.length; i++) view.setUint8(offset + i, str.charCodeAt(i));
  }

  writeString(0, "RIFF");
  view.setUint32(4, 36 + dataSize, true);
  writeString(8, "WAVE");
  writeString(12, "fmt ");
  view.setUint32(16, 16, true);        // PCM chunk size
  view.setUint16(20, 1, true);         // audio format = PCM
  view.setUint16(22, numChannels, true);
  view.setUint32(24, sampleRate, true);
  view.setUint32(28, byteRate, true);
  view.setUint16(32, blockAlign, true);
  view.setUint16(34, 16, true);        // bits per sample
  writeString(36, "data");
  view.setUint32(40, dataSize, true);
}

function floatTo16BitPCM(output, offset, input) {
  for (let i = 0; i < input.length; i++) {
    let s = Math.max(-1, Math.min(1, input[i]));
    output.setInt16(offset, s < 0 ? s * 0x8000 : s * 0x7fff, true);
    offset += 2;
  }
}

async function convertToWav(blob) {
  const arrayBuffer = await blobToArrayBuffer(blob);
  const audioCtx = new (window.AudioContext || window.webkitAudioContext)();
  const audioBuffer = await audioCtx.decodeAudioData(arrayBuffer.slice(0));

  const numChannels = audioBuffer.numberOfChannels;
  const sampleRate = audioBuffer.sampleRate;
  const numFrames = audioBuffer.length;

  // Interleave channels
  const interleaved = new Float32Array(numFrames * numChannels);
  for (let ch = 0; ch < numChannels; ch++) {
    const channelData = audioBuffer.getChannelData(ch);
    for (let i = 0; i < numFrames; i++) {
      interleaved[i * numChannels + ch] = channelData[i];
    }
  }

  const buffer = new ArrayBuffer(44 + numFrames * numChannels * 2);
  const view = new DataView(buffer);
  writeWavHeader(view, sampleRate, numChannels, numFrames);
  floatTo16BitPCM(view, 44, interleaved);

  return new Blob([view], { type: "audio/wav" });
}

      async function startRecording() {
        micStatusEl.textContent = "Requesting microphone‚Ä¶";
        transcriptEl.textContent = "Listening‚Ä¶";
        replyEl.textContent = "‚Äî";
        chunks = [];

        let stream;
        try {
          stream = await navigator.mediaDevices.getUserMedia({ audio: true });
        } catch (err) {
          micStatusEl.textContent = `‚ùå Mic blocked: ${err.name} ‚Äî ${err.message || ""}`;
          throw err;
        }

        currentStream = stream;

        if (!window.MediaRecorder) {
          micStatusEl.textContent = "‚ùå MediaRecorder not supported on this device.";
          throw new Error("MediaRecorderNotAvailable");
        }

        const candidates = ["audio/webm;codecs=opus","audio/webm","audio/mp4","audio/aac"];
        let chosen = "";
        for (const t of candidates) {
          if (MediaRecorder.isTypeSupported(t)) { chosen = t; break; }
        }

        mediaRecorder = chosen ? new MediaRecorder(stream, { mimeType: chosen }) : new MediaRecorder(stream);

        mediaRecorder.ondataavailable = (e) => {
          if (e.data && e.data.size > 0) chunks.push(e.data);
        };

        mediaRecorder.onerror = (e) => {
          micStatusEl.textContent = `‚ùå Recorder error: ${e.error?.name || "unknown"}`;
        };

        mediaRecorder.start();
        micStatusEl.textContent = "‚úÖ Recording‚Ä¶";
      }

      async function stopRecording() {
        if (!mediaRecorder) return;

        return new Promise((resolve) => {
          mediaRecorder.onstop = () => {
            // ‚úÖ stop mic tracks so next recording works on iOS
            if (currentStream) {
              currentStream.getTracks().forEach(t => t.stop());
              currentStream = null;
            }
            mediaRecorder = null;
            resolve();
          };

          // ‚úÖ flush final chunk (helps iOS)
          try { mediaRecorder.requestData(); } catch {}

          setTimeout(() => {
            try { mediaRecorder.stop(); } catch { resolve(); }
          }, 120);
        });
      }

      async function sendToServer(blob) {
        transcriptEl.textContent = "Sending‚Ä¶";

        const fd = new FormData();

        const mime = blob.type || "";
        let ext = "webm";
        if (mime.includes("mp4")) ext = "mp4";
        else if (mime.includes("ogg")) ext = "ogg";
        else if (mime.includes("wav")) ext = "wav";
        else if (mime.includes("mpeg")) ext = "mp3";

        fd.append("audio", blob, `speech.${ext}`);
        fd.append("mode", modeEl.value);
        fd.append("session_id", sessionId);

        const controller = new AbortController();
        const t = setTimeout(() => controller.abort(), 45000);

        try {
          const res = await fetch("/talk", { method: "POST", body: fd, signal: controller.signal });

          if (res.status === 401) {
            window.location.href = "/login";
            return;
          }

          if (!res.ok) {
            const text = await res.text();
            transcriptEl.textContent = `Server error (${res.status})`;
            replyEl.textContent = text.slice(0, 400);
            micStatusEl.textContent = "‚ùå Send failed (server)";
            return;
          }

          const data = await res.json();

          if (data.session_id) {
            sessionId = data.session_id;
            localStorage.setItem("sessionId", sessionId);
          }

          transcriptEl.textContent = data.transcript || "‚Äî";
          replyEl.textContent = data.reply || "‚Äî";

          if (data.audio_b64) {
            player.src = "data:audio/mp3;base64," + data.audio_b64;
            try { await player.play(); } catch {}
          }

          micStatusEl.textContent = "‚úÖ Done";
        } catch (err) {
          micStatusEl.textContent = "‚ùå Send failed";
          replyEl.textContent =
            err.name === "AbortError"
              ? "Timed out waiting for server."
              : (err.message || String(err));
        } finally {
          clearTimeout(t);
        }
      }

      // Pointer events = Windows + iOS
      talkBtn.addEventListener("pointerdown", async (e) => {
        e.preventDefault();
        if (isRecording) return;

        try {
          await startRecording();
          isRecording = true;
          talkBtn.textContent = "‚è∫Ô∏è Recording‚Ä¶ release to send";
        } catch {
          replyEl.textContent = "Mic start failed (see Mic status).";
        }
      });

      async function finishRecording(e) {
        e.preventDefault();
        if (!isRecording) return;

        await stopRecording();
        isRecording = false;
        talkBtn.textContent = "üé§ Hold to talk";

        if (!chunks.length) {
          transcriptEl.textContent = "No audio captured. Try again.";
          micStatusEl.textContent = "‚ùå No audio";
          return;
        }

        const blobType = (chunks[0] && chunks[0].type) ? chunks[0].type : "audio/webm";
        let blob = new Blob(chunks, { type: blobType });
        // ‚úÖ If Windows/Chrome gives webm, convert to WAV for OpenAI reliability
if (blobType.includes("webm")) {
  micStatusEl.textContent = "Converting audio‚Ä¶";
  try {
    blob = await convertToWav(blob);
  } catch (e) {
    // if conversion fails, still try original blob
    console.warn("WAV conversion failed:", e);
  }
}
        await sendToServer(blob);
      }

      talkBtn.addEventListener("pointerup", finishRecording);
      talkBtn.addEventListener("pointercancel", finishRecording);

      resetBtn.addEventListener("click", async () => {
        try {
          await fetch("/reset", {
            method: "POST",
            headers: { "Content-Type": "application/json" },
            body: JSON.stringify({ session_id: sessionId })
          });
        } catch {}

        sessionId = "";
        localStorage.removeItem("sessionId");
        transcriptEl.textContent = "‚Äî";
        replyEl.textContent = "Conversation reset. Sag: ‚ÄûHallo!‚Äú üôÇ";
        micStatusEl.textContent = "‚Äî";
        player.src = "";
      });
    </script>
  </div>
</body>
</html>